# Generative AI with Large Language Models (LLMs) – Coursera

This repository accompanies the **"Generative AI with Large Language Models (LLMs)"** course, offered by DeepLearning.AI in collaboration with AWS on [Coursera](https://www.coursera.org/learn/generative-ai-with-llms)
---

##  What’s Inside

- **`notes/`**  
  Markdown files capturing lecture summaries, architectural diagrams (e.g., Transformer), key concepts like prompt engineering, scaling laws, and deployment insights.

- **`labs/`**  
  Jupyter notebooks featuring practical, hands-on exercises (e.g., exploring LLM inference, implementing fine-tuning workflows, or prompt experiments).

---

##  Course Overview

In this intermediate-level course (~2 weeks at ~10 hours/week), you'll:

- Build foundational knowledge of **generative AI and LLMs**, including the transformer architecture, training lifecycle, and deployment scenarios.  
- Learn about **empirical scaling laws** to optimize datasets, compute budgets, and inference performance.
- Explore how to **fine-tune models**, leverage prompt engineering, and apply massive model deployment techniques within real-world constraints.

---

##  Why Follow Along?

Whether you're a data scientist, ML engineer, or prompt enthusiast, this course provides the right balance of theory and application to build your practical intuition about LLMs in business and AI projects.

---

##  Repository Structure

```text
Generative-AI-with-LLMs/
├── notes/ # Markdown lecture summaries
├── labs/ # Jupyter notebooks with hands-on work
└── README.md # This overview
```


---

##  Getting Started

1. Explore the **notes** to grasp the fundamentals of generative AI and LLMs.
2. Run the **notebooks in labs** to deepen your practical skills—fine-tuning, prompt experiments, and more.
3. Customize or expand based on your learning goals!

---

Hope this README helps others understand what's included and what they can achieve.
